{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estructura\n",
    "\n",
    "Claves:\n",
    "1. Conexión con modelos\n",
    "2. Conexión con datos\n",
    "3. Encadenamiento de procesos\n",
    "\n",
    "\n",
    "https://python.langchain.com/docs/integrations/providers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinguillencisneros/Downloads/Developing_applications_with_Langchain/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
      "\n",
      "Fetching 2 files: 100%|██████████| 2/2 [03:21<00:00, 100.80s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the disk.\n",
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "# model = \"tiiuae/falcon-40b-instruct\" # Generacion de texto\n",
    "# model = \"stabilityai/stablelm-tuned-alpha-3b\"\n",
    "model = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer= tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.pipelines.text_generation.TextGenerationPipeline"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFacePipeline\n",
    "\n",
    "llm_falcon = HuggingFacePipeline(\n",
    "    pipeline = pipeline,\n",
    "    model_kwargs = {\n",
    "        \"temperature\": 0,\n",
    "        \"max_length\": 200,\n",
    "        \"do_sample\": True,\n",
    "        \"top_k\": 10,\n",
    "        \"num_return_sequences\": 1,\n",
    "        \"eos_token_id\": tokenizer.eos_token_id\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x10fdceba0>, model_kwargs={'temperature': 0, 'max_length': 200, 'do_sample': True, 'top_k': 10, 'num_return_sequences': 1, 'eos_token_id': 11})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_falcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0z/s0pfsfdn61b_3c4kn01_hktc0000gn/T/ipykernel_17503/1947423762.py:1: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  llm_falcon(\"what is AI?\")\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'what is AI?\\nAI stands for Artificial Intelligence. It is a branch of computer science that focuses on creating intelligent machines'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_falcon(\"what is AI?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models with openAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPEN_AI_KEY\")\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm_gpt3_5 = ChatOpenAI(\n",
    "    model_name = \"gpt-3.5-turbo\",\n",
    "    n = 1, #numero de diferentes respuestas\n",
    "    temperature = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x16abe9fd0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x16abf67b0>, root_client=<openai.OpenAI object at 0x16a847b60>, root_async_client=<openai.AsyncOpenAI object at 0x16abea120>, temperature=0.3, model_kwargs={}, openai_api_key=SecretStr('**********'), n=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_gpt3_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Para lograr una clase más interactiva para estudiantes virtuales, puedes implementar las siguientes estrategias:\\n\\n1. Utilizar herramientas de videoconferencia que permitan la participación activa de los estudiantes, como la función de chat, la posibilidad de levantar la mano para hacer preguntas o comentar, y la opción de compartir la pantalla para mostrar trabajos o presentaciones.\\n\\n2. Fomentar la participación de los estudiantes a través de preguntas abiertas, encuestas en tiempo real, debates y discusiones grupales.\\n\\n3. Utilizar herramientas de colaboración en línea, como Google Docs o Padlet, para que los estudiantes puedan trabajar juntos en proyectos y compartir ideas de forma simultánea.\\n\\n4. Incorporar actividades interactivas, como juegos educativos, cuestionarios en línea, simulaciones y ejercicios prácticos, que motiven a los estudiantes a participar activamente en la clase.\\n\\n5. Proporcionar retroalimentación constante a los estudiantes, tanto individualmente como en grupo, para mantener su interés y motivación durante la clase.\\n\\n6. Organizar sesiones de tutoría individual o en pequeños grupos para brindar apoyo personalizado a los estudiantes y fomentar la interacción entre ellos.\\n\\n7. Promover la participación activa de los estudiantes a través de la asignación de roles y responsabilidades dentro de la clase, como líder de grupo, moderador de discusiones o presentador de trabajos.\\n\\nAl implementar estas estrategias, podrás crear una experiencia de aprendizaje más dinámica y participativa para tus estudiantes virtuales, lo que les permitirá sentirse más comprometidos y motivados en su proceso de aprendizaje.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 372, 'prompt_tokens': 22, 'total_tokens': 394, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BLwKJA6NtDWVf2WAlV2vMnTwEyzZL', 'finish_reason': 'stop', 'logprobs': None}, id='run-138331ee-12af-49f9-8313-83032a84310e-0', usage_metadata={'input_tokens': 22, 'output_tokens': 372, 'total_tokens': 394, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_gpt3_5.invoke('Como puedo lograr una clase mas interaciva para estudiantes virtuales?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_davinci = ChatOpenAI(\n",
    "    model_name = \"text-davinci-003\",\n",
    "    n = 2, #numero de diferentes respuestas\n",
    "    temperature = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "generacion = llm_gpt3_5.generate(\n",
    "    [\n",
    "        \"Dime un consejo de vida para alguien de 30 años\",\n",
    "        \"Recomiendame libros similares a Hyperion Cantos\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatGeneration(text='No te compares con los demás, cada persona tiene su propio camino y ritmo de vida. Enfócate en tus metas y sueños, trabaja duro para alcanzarlos y disfruta el proceso. Aprovecha cada oportunidad que se te presente y no tengas miedo de tomar riesgos. Recuerda que nunca es tarde para empezar de nuevo o cambiar de dirección si es lo que realmente deseas. Vive el presente, aprende del pasado y visualiza un futuro brillante.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='No te compares con los demás, cada persona tiene su propio camino y ritmo de vida. Enfócate en tus metas y sueños, trabaja duro para alcanzarlos y disfruta el proceso. Aprovecha cada oportunidad que se te presente y no tengas miedo de tomar riesgos. Recuerda que nunca es tarde para empezar de nuevo o cambiar de dirección si es lo que realmente deseas. Vive el presente, aprende del pasado y visualiza un futuro brillante.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 107, 'prompt_tokens': 20, 'total_tokens': 127, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BLwQ8CbAf66OSugN1MkdRYlkat1X7', 'finish_reason': 'stop', 'logprobs': None}, id='run-9dfaee54-f71a-4d9f-92db-bfe0de47b3be-0', usage_metadata={'input_tokens': 20, 'output_tokens': 107, 'total_tokens': 127, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}))]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generacion.generations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatGeneration(text='1. \"Dune\" by Frank Herbert - A classic science fiction novel that explores themes of politics, religion, and ecology in a richly imagined universe.\\n\\n2. \"The Expanse series\" by James S.A. Corey - A gripping space opera series that follows a diverse cast of characters as they navigate political intrigue and interstellar conflict.\\n\\n3. \"Foundation series\" by Isaac Asimov - A seminal work of science fiction that explores the rise and fall of civilizations in a vast galactic empire.\\n\\n4. \"Altered Carbon\" by Richard K. Morgan - A gritty cyberpunk novel that follows a former soldier turned private investigator as he navigates a world where consciousness can be transferred between bodies.\\n\\n5. \"The Culture series\" by Iain M. Banks - A series of space opera novels that explore a post-scarcity society run by artificial intelligences known as the Culture.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='1. \"Dune\" by Frank Herbert - A classic science fiction novel that explores themes of politics, religion, and ecology in a richly imagined universe.\\n\\n2. \"The Expanse series\" by James S.A. Corey - A gripping space opera series that follows a diverse cast of characters as they navigate political intrigue and interstellar conflict.\\n\\n3. \"Foundation series\" by Isaac Asimov - A seminal work of science fiction that explores the rise and fall of civilizations in a vast galactic empire.\\n\\n4. \"Altered Carbon\" by Richard K. Morgan - A gritty cyberpunk novel that follows a former soldier turned private investigator as he navigates a world where consciousness can be transferred between bodies.\\n\\n5. \"The Culture series\" by Iain M. Banks - A series of space opera novels that explore a post-scarcity society run by artificial intelligences known as the Culture.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 181, 'prompt_tokens': 20, 'total_tokens': 201, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BLwQ9gTP1hzZTPsqGpsIaU4oMQlUJ', 'finish_reason': 'stop', 'logprobs': None}, id='run-cf5c8e22-feb5-41ff-b366-fdc903b5b57c-0', usage_metadata={'input_tokens': 20, 'output_tokens': 181, 'total_tokens': 201, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}))]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generacion.generations[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 288,\n",
       "  'prompt_tokens': 40,\n",
       "  'total_tokens': 328,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-3.5-turbo'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generacion.llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_gpt3_5.get_num_tokens('Mis jefes se van a preocupar si gasto mucho en openai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
