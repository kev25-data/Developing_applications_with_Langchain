{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPEN_AI_KEY = os.getenv(\"OPEN_AI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargado paper1.pdf\n",
      "Descargado paper2.pdf\n",
      "Descargado paper3.pdf\n",
      "Descargado paper4.pdf\n",
      "Descargado paper5.pdf\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "urls = [\n",
    "    'https://arxiv.org/pdf/2306.06031v1.pdf',\n",
    "    'https://arxiv.org/pdf/2306.12156v1.pdf',\n",
    "    'https://arxiv.org/pdf/2306.14289v1.pdf',\n",
    "    'https://arxiv.org/pdf/2305.10973v1.pdf',\n",
    "    'https://arxiv.org/pdf/2306.13643v1.pdf'\n",
    "]\n",
    "\n",
    "ml_papers = []\n",
    "\n",
    "for i, url in enumerate(urls):\n",
    "    response =  requests.get(url)\n",
    "    filename = f'paper{i+1}.pdf'\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "        print(f'Descargado {filename}') \n",
    "\n",
    "        loader = PyPDFLoader(filename) # Cargar la info que queremos (el nombre del documento)\n",
    "        data = loader.load() # load vamos a tener un document, una clase paara que langchain procese su info\n",
    "        ml_papers.extend(data) # Tener una gran lista para unir los pdfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list,\n",
       " 57,\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-06-12T00:32:18+00:00', 'author': '', 'keywords': '', 'moddate': '2023-06-12T00:32:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'templateversion': 'IJCAI.2023.0', 'title': '', 'trapped': '/False', 'source': 'paper1.pdf', 'total_pages': 7, 'page': 4, 'page_label': '5'}, page_content='ingest data in real-time. This data could be streaming from\\nour data source APIs. Below are the steps to design a real-\\ntime NLP pipeline for data ingestion.\\nData cleaning: Real-time data can be noisy and inconsis-\\ntent. Therefore, real-time data cleaning involves removing\\nirrelevant data, handling missing values, text normalization\\n(like lowercasing), and error corrections.\\nTokenization: In real-time applications, tokenization has\\nto be performed on the fly. This involves breaking down the\\nstream of text into smaller units or tokens.\\nStop word removal and stemming/lemmatization : For\\nreal-time processing, a predefined list of stop words can be\\nused to filter out these common words from the stream of\\ntokens. Likewise, stemming and lemmatization techniques\\ncan be applied to reduce words to their root form.\\nFeature extraction and sentiment analysis : Feature ex-\\ntraction involves transforming raw data into an input that can\\nbe understood by machine learning models. In real-time sys-\\ntems, this often needs to be a fast and efficient process. Tech-\\nniques such as TF-IDF, Bag of Words, or embedding vectors\\nlike Word2Vec can be used. Sentiment analysis can also be\\nperformed on the cleaned data. This is where we categorize a\\nspan of text as positive, negative, or neutral.\\nPrompt engineering: The creation of effective prompts\\nthat can guide the language model’s generation process to-\\nward desirable outputs.\\nAlerts/Decision making: Once the prompt is entered, the\\nresults need to be communicated or acted upon. This might\\ninvolve triggering alerts based on certain conditions, inform-\\ning real-time decision-making processes, or feeding the out-\\nput into another system.\\nContinuous learning : In real-time systems, the models\\nshould adapt to changes in the data. Continuous learning sys-\\ntems can be implemented, where models are periodically re-\\ntrained on new data or online learning algorithms are used\\nthat can update the model with each new data point.\\nMonitoring: Real-time systems require continuous mon-\\nitoring to ensure they are functioning correctly. Any delays\\nor issues in the pipeline can have immediate impacts, so it’s\\nimportant to have robust monitoring and alerting in place.\\n4.3 Large Language Models (LLMs)\\nOnce the data has been properly prepared, it is used with\\nLLMs to generate insightful financial analyses. The LLM\\nlayer includes:\\n• LLM APIs: APIs from established LLMs provide baseline\\nlanguage capability.\\n• Trainable models: FinGPT provides trainable models that\\nusers can fine-tune on their private data, customizing for\\nfinancial applications.\\n• Fine-tuning methods: Various fine-tuning methods allow\\nFinGPT to be adapted to personalized robo-advisor.\\nWhy fine-tune LLMs instead of retraining from scratch?\\nLeveraging pre-existing Large Language Models (LLMs)\\nand fine-tuning them for finance provides an efficient, cost-\\neffective alternative to expensive and lengthy model retrain-\\ning from scratch.\\nBloombergGPT, though remarkable in its finance-specific\\ncapabilities, comes with an intensive computational require-\\nment. It used approximately 1.3 million GPU hours for train-\\ning, which, when calculated using AWS cloud’s $2.3 rate,\\ntranslates to a staggering cost of around $3 million per train-\\ning. In contrast to the high computational cost of models like\\nBloombergGPT, FinGPT presents a more accessible solution\\nby focusing on the lightweight adaptation of top open-source\\nLLMs. The cost of adaptation falls significantly, estimated at\\nless than $300 per training.\\nThis approach ensures timely updates and adaptability, es-\\nsential in the dynamic financial domain. Being open-source,\\nFinGPT not only promotes transparency but also allows\\nuser customization, catering to the rising trend of personal-\\nized financial advisory services. Ultimately, FinGPT’s cost-\\neffective, flexible framework holds the potential to democra-\\ntize financial language modeling and foster user-focused fi-\\nnancial services.\\nFine-tuning via Low-rank Adaptation (LoRA)\\nIn FinGPT, we fine-tune to a pre-trained LLM utilizing a\\nnovel financial dataset. It’s well recognized that high-quality\\nlabeled data is a pivotal determinant for many successful\\nLLMs, including ChatGPT. However, acquiring such top-\\nnotch labeled data often proves costly in terms of time and\\nresources and generally requires the expertise of finance pro-\\nfessionals.\\nIf our objective is to employ LLMs for analyzing financial-\\nrelated text data and assisting in quantitative trading, it seems\\nsensible to leverage the market’s inherent labeling capac-\\nity. Consequently, we use the relative stock price change\\npercentage for each news item as the output label. We\\nestablish thresholds to divide these labels into three cate-\\ngories—positive, negative, and neutral—based on the senti-\\nment of the news item.\\nIn a corresponding step, during the prompt engineering\\nprocess, we also prompt the model to select one from the pos-\\nitive, negative, and neutral outputs. This strategy ensures op-\\ntimal utilization of the pre-trained information. By deploying\\nthe Low-Rank Adaptation (LoRA) of LLMs [Hu et al., 2021;\\nDettmers et al., 2023], we manage to reduce the number of\\ntrainable parameters from 6.17 billion to a mere 3.67 million.\\nFine-tuning via Reinforcement Learning on Stock Prices\\n(RLSP)\\nSimilarly, we can substitute Reinforcement Learning on\\nStock Prices (RLSP) for Reinforcement Learning on Human\\nfeedback, as utilized by ChatGPT. The reasoning behind this\\nsubstitution is that stock prices offer a quantifiable, objective\\nmetric that reflects market sentiment in response to news and\\nevents. This makes it a robust, real-time feedback mechanism\\nfor training our model.\\nReinforcement Learning (RL) allows the model to learn\\nthrough interaction with the environment and receiving feed-\\nback. In the case of RLSP, the environment is the stock\\nmarket, and the feedback comes in the form of stock price\\nchanges. This approach permits FinGPT to refine its under-\\nstanding and interpretation of financial texts, improving its\\nability to predict market responses to various financial events.'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ml_papers), len(ml_papers), ml_papers[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir el texto n numero con embbedings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter =  RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500, # Total de caracteres\n",
    "    chunk_overlap = 200, # Caracteres que se comparten con el siguiente chunk\n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "documents =  text_splitter.split_documents(ml_papers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211,\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-06-12T00:32:18+00:00', 'author': '', 'keywords': '', 'moddate': '2023-06-12T00:32:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'templateversion': 'IJCAI.2023.0', 'title': '', 'trapped': '/False', 'source': 'paper1.pdf', 'total_pages': 7, 'page': 2, 'page_label': '3'}, page_content='highly volatile, changing rapidly in response to news events\\nor market movements.\\nTrends, often observable through websites like Seeking\\nAlpha, Google Trends, and other finance-oriented blogs and\\nforums, offer critical insights into market movements and in-\\nvestment strategies. They feature:\\n• Analyst perspectives: These platforms provide access to\\nmarket predictions and investment advice from seasoned\\nfinancial analysts and experts.\\n• Market sentiment: The discourse on these platforms can\\nreflect the collective sentiment about specific securities,\\nsectors, or the overall market, providing valuable insights\\ninto the prevailing market mood.\\n• Broad coverage: Trends data spans diverse securities and\\nmarket segments, offering comprehensive market coverage.\\nEach of these data sources provides unique insights into\\nthe financial world. By integrating these diverse data types,\\nfinancial language models like FinGPT can facilitate a com-\\nprehensive understanding of financial markets and enable ef-\\nfective financial decision-making.\\n3.2 Challenges in Handling Financial Data\\nWe summarize three major challenges for handling financial\\ndata as follows:\\n• High temporal sensitivity : Financial data are character-\\nized by their time-sensitive nature. Market-moving news or\\nupdates, once released, provide a narrow window of oppor-\\ntunity for investors to maximize their alpha (the measure of\\nan investment’s relative return).\\n• High dynamism : The financial landscape is perpetually'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents), documents[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings e ingsta a base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0z/s0pfsfdn61b_3c4kn01_hktc0000gn/T/ipykernel_46235/2810570532.py:4: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings =  OpenAIEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "embeddings =  OpenAIEmbeddings(\n",
    "    openai_api_key = OPEN_AI_KEY, \n",
    "    model ='text-embedding-ada-002'\n",
    ")\n",
    "\n",
    "vectorstore =  Chroma.from_documents(\n",
    "    documents = documents,\n",
    "    embedding = embeddings\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs = {\"k\":3}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de chat y cadenas para consulta de informacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0z/s0pfsfdn61b_3c4kn01_hktc0000gn/T/ipykernel_46235/2637932081.py:6: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo de lenguaje que resolvera la pregunta\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key = OPEN_AI_KEY,\n",
    "    model_name = 'gpt-3.5-turbo',\n",
    "    temperature =  0.0\n",
    ")\n",
    "\n",
    "qa_chain =  RetrievalQA.from_chain_type(\n",
    "    llm = chat,\n",
    "    chain_type= \"stuff\",\n",
    "    retriever = retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FinGPT es un modelo de lenguaje de código abierto diseñado para el procesamiento de lenguaje natural en el ámbito financiero. Se enfoca en aprovechar el potencial de los modelos de lenguaje grandes para aplicaciones financieras, como servicios de asesoramiento robótico, trading cuantitativo y desarrollo de bajo código. FinGPT adopta un enfoque centrado en los datos y cuenta con un marco de trabajo de extremo a extremo con cuatro capas para garantizar la calidad de los datos y abordar la sensibilidad temporal de los datos financieros. Además, FinGPT forma parte de la comunidad de inteligencia artificial AI4Finance, con el objetivo de fomentar la innovación, democratizar los modelos de lenguaje financiero y desbloquear nuevas oportunidades en finanzas abiertas.\n"
     ]
    }
   ],
   "source": [
    "query = \"Que es fingpt?\"\n",
    "print(qa_chain.invoke(query)['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
